{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaComputing/JuliaAcademyData.jl`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[2K\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `C:\\Users\\sousa\\.julia\\registries\\General`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Authentication required.\n",
      "Opening https://pkg.juliahub.com/auth/response?28b42c610386ae1dadced4006998a2d5 to authenticate.\n",
      "\n",
      "Authentication timed out. Please try again.\n",
      "\n",
      "Alternatively, open\n",
      "\n",
      "https://pkg.juliahub.com/auth\n",
      "\n",
      "in a browser, authenticate, and save the downloaded file at\n",
      "\n",
      "C:\\Users\\sousa\\.julia\\servers\\pkg.juliahub.com\\auth.toml\n",
      "\n",
      "Press Enter when you're done...\n",
      "\n",
      "\n",
      "Authentication required.\n",
      "Opening https://pkg.juliahub.com/auth/response?aeee0d8ae140ced5f04387e31d0a5f81 to authenticate.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Error: JuliaTeam authentication handler failed.\n",
      "└ @ Main C:\\Users\\sousa\\AppData\\Local\\JuliaPro-1.5.3-1\\Julia-1.5.3\\etc\\julia\\startup.jl:26\n",
      "┌ Warning: could not download https://pkg.juliahub.com/registries\n",
      "└ @ Pkg.Types C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\Types.jl:951\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `C:\\Users\\sousa\\.julia\\registries\\JuliaComputingRegistry`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m "
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] try_yieldto(::typeof(Base.ensure_rescheduled)) at .\\task.jl:656",
      " [2] wait at .\\task.jl:713 [inlined]",
      " [3] uv_write(::Base.PipeEndpoint, ::Ptr{UInt8}, ::UInt64) at .\\stream.jl:933",
      " [4] unsafe_write(::Base.PipeEndpoint, ::Ptr{UInt8}, ::UInt64) at .\\stream.jl:1005",
      " [5] unsafe_write at .\\io.jl:337 [inlined]",
      " [6] write at .\\strings\\io.jl:183 [inlined]",
      " [7] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::String) at .\\strings\\io.jl:185",
      " [8] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::String, ::String, ::Vararg{Any,N} where N) at .\\strings\\io.jl:46",
      " [9] println at .\\strings\\io.jl:73 [inlined]",
      " [10] printpkgstyle(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::Symbol, ::String, ::Bool) at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\Types.jl:1353",
      " [11] printpkgstyle(::Pkg.Types.Context, ::Symbol, ::String, ::Bool) at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\Types.jl:1347",
      " [12] print_status(::Pkg.Types.Context, ::Pkg.Types.Context, ::Symbol, ::Array{Union{Nothing, Base.UUID},1}, ::Array{Union{Nothing, String},1}; manifest::Bool, diff::Bool) at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\Operations.jl:1691",
      " [13] status(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; header::Symbol, mode::Pkg.Types.PackageMode, git_diff::Bool, env_diff::Pkg.Types.EnvCache) at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\Operations.jl:1775",
      " [14] show_update at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\Operations.jl:1742 [inlined]",
      " [15] add(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}, ::Array{Base.UUID,1}; preserve::Pkg.Types.PreserveLevel, platform::Pkg.BinaryPlatforms.Windows) at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\Operations.jl:1144",
      " [16] add(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; preserve::Pkg.Types.PreserveLevel, platform::Pkg.BinaryPlatforms.Windows, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\API.jl:188",
      " [17] add(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\API.jl:139",
      " [18] #add#21 at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\API.jl:67 [inlined]",
      " [19] add at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\API.jl:67 [inlined]",
      " [20] #add#19 at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\API.jl:65 [inlined]",
      " [21] add(::Pkg.Types.PackageSpec) at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.5\\Pkg\\src\\API.jl:65",
      " [22] top-level scope at In[1]:1",
      " [23] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091",
      " [24] execute_code(::String, ::String) at C:\\Users\\sousa\\.julia\\packages\\IJulia\\a1SNk\\src\\execute_request.jl:27",
      " [25] execute_request(::ZMQ.Socket, ::IJulia.Msg) at C:\\Users\\sousa\\.julia\\packages\\IJulia\\a1SNk\\src\\execute_request.jl:86",
      " [26] #invokelatest#1 at .\\essentials.jl:710 [inlined]",
      " [27] invokelatest at .\\essentials.jl:709 [inlined]",
      " [28] eventloop(::ZMQ.Socket) at C:\\Users\\sousa\\.julia\\packages\\IJulia\\a1SNk\\src\\eventloop.jl:8",
      " [29] (::IJulia.var\"#15#18\")() at .\\task.jl:356"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(Pkg.PackageSpec(url=\"https://github.com/JuliaComputing/JuliaAcademyData.jl\"))\n",
    "using JuliaAcademyData; activate(\"Parallel_Computing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia is fast\n",
    "\n",
    "Very often, benchmarks are used to compare languages.  These benchmarks can\n",
    "lead to long discussions, first as to exactly what is being benchmarked and\n",
    "secondly what explains the differences.  These simple questions can sometimes\n",
    "get more complicated than you at first might imagine.\n",
    "\n",
    "The purpose of this notebook is for you to see a simple benchmark for\n",
    "yourself.\n",
    "\n",
    "(This material began life as a wonderful lecture by Steven Johnson at MIT:\n",
    "[Boxes and registers](https://github.com/stevengj/18S096/blob/master/lectures/lecture1/Boxes-and-registers.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of this notebook\n",
    "\n",
    "- Define the sum function\n",
    "- Implementations & benchmarking of sum in...\n",
    "    - Julia (built-in)\n",
    "    - Julia (hand-written)\n",
    "    - C (hand-written)\n",
    "    - python (built-in)\n",
    "    - python (numpy)\n",
    "    - python (hand-written)\n",
    "- Towards exploiting parallelism with Julia\n",
    "    - Allowing for floating point associativity\n",
    "    - Making use of four cores at once: built-in\n",
    "    - Making use of four cores at once: hand-written\n",
    "- Summary of benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `sum`: An easy enough function to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the  **sum** function `sum(a)`, which computes\n",
    "$$\n",
    "\\mathrm{sum}(a) = \\sum_{i=1}^n a_i,\n",
    "$$\n",
    "where $n$ is the length of `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000-element Array{Float64,1}:\n",
       " 0.060110004256964666\n",
       " 0.5075683180456987\n",
       " 0.7636466694987871\n",
       " 0.6607076459441128\n",
       " 0.13507532380562526\n",
       " 0.41564505104428173\n",
       " 0.614973115832165\n",
       " 0.07046585215131396\n",
       " 0.7505256378959506\n",
       " 0.7800016074961564\n",
       " 0.7544460660951431\n",
       " 0.8903312171950961\n",
       " 0.8658310960102851\n",
       " ⋮\n",
       " 0.7046125024046077\n",
       " 0.05148866164628507\n",
       " 0.8510370827407661\n",
       " 0.4234616805670315\n",
       " 0.31963901571974396\n",
       " 0.36369666616688456\n",
       " 0.8455728727601841\n",
       " 0.27424443210282523\n",
       " 0.31273165168030803\n",
       " 0.6725592693063593\n",
       " 0.6035733570002384\n",
       " 0.27819316199496136"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = rand(10^7) # 1D vector of random numbers, uniform on [0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000992326781889e6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected result is ~0.5 * 10^7, since the mean of each entry is 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking a few ways in a few languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.012496 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.000351514035497e6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.006031 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.000351514035497e6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.006442 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.000351514035497e6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@time` macro can yield noisy results, so it's not our best choice for benchmarking!\n",
    "\n",
    "Luckily, Julia has a `BenchmarkTools.jl` package to make benchmarking easy and accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     5.319 ms (0.00% GC)\n",
       "  median time:      6.069 ms (0.00% GC)\n",
       "  mean time:        6.690 ms (0.00% GC)\n",
       "  maximum time:     38.263 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          747\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark sum($a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Julia Built-in\n",
    "\n",
    "So that's the performance of Julia's built-in sum — but that could be doing any number of tricks to be fast, including not using Julia at all in the first place! Of course, it is indeed written in Julia, but would it perform if we write a naive implementation ourselves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "sum(a::<b>AbstractArray</b>; <i>dims</i>) in Base at <a href=\"https://github.com/JuliaLang/julia/tree/788b2c77c10c2160f4794a4d4b6b81a95a90940c/base/reducedim.jl#L722\" target=\"_blank\">reducedim.jl:722</a>"
      ],
      "text/plain": [
       "sum(a::AbstractArray; dims) in Base at reducedim.jl:722"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save these benchmark results to a dictionary so we can start keeping track of them and comparing them down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     5.651 ms (0.00% GC)\n",
       "  median time:      8.023 ms (0.00% GC)\n",
       "  mean time:        9.029 ms (0.00% GC)\n",
       "  maximum time:     29.978 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          554\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench = @benchmark sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 1 entry:\n",
       "  \"Julia built-in\" => 5.651"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Dict()\n",
    "d[\"Julia built-in\"] = minimum(j_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Julia (hand-written)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum(A)\n",
    "    s = 0.0\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     12.026 ms (0.00% GC)\n",
       "  median time:      12.712 ms (0.00% GC)\n",
       "  mean time:        12.988 ms (0.00% GC)\n",
       "  maximum time:     21.073 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          385\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand = @benchmark mysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 2 entries:\n",
       "  \"Julia hand-written\" => 12.0256\n",
       "  \"Julia built-in\"     => 5.651"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia hand-written\"] = minimum(j_bench_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's about 2x slower than the builtin definition. We'll see why later on.\n",
    "\n",
    "But first: is this fast?  How would we know?  Let's compare it to some other languages..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. The C language\n",
    "\n",
    "C is often considered the gold standard: difficult on the human, nice for the machine. Getting within a factor of 2 of C is often satisfying. Nonetheless, even within C, there are many kinds of optimizations possible that a naive C writer may or may not get the advantage of.\n",
    "\n",
    "The current author does not speak C, so he does not read the cell below, but is happy to know that you can put C code in a Julia session, compile it, and run it. Note that the `\"\"\"` wrap a multi-line string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Libdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_sum (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "C_code = \"\"\"\n",
    "    #include <stddef.h>\n",
    "    double c_sum(size_t n, double *X) {\n",
    "        double s = 0.0;\n",
    "        for (size_t i = 0; i < n; ++i) {\n",
    "            s += X[i];\n",
    "        }\n",
    "        return s;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "const Clib = tempname()   # make a temporary file\n",
    "\n",
    "\n",
    "# compile to a shared library by piping C_code to gcc\n",
    "# (works only if you have gcc installed):\n",
    "\n",
    "open(`gcc -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code)\n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum(X::Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "could not load library \"C:\\Users\\sousa\\AppData\\Local\\Temp\\jl_WsKMrQXsBj\"\n%1 não é um aplicativo Win32 válido. ",
     "output_type": "error",
     "traceback": [
      "could not load library \"C:\\Users\\sousa\\AppData\\Local\\Temp\\jl_WsKMrQXsBj\"\n%1 não é um aplicativo Win32 válido. ",
      "",
      "Stacktrace:",
      " [1] c_sum(::Array{Float64,1}) at .\\In[18]:24",
      " [2] top-level scope at In[19]:1",
      " [3] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "c_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sum(a) ≈ sum(a) # type \\approx and then <TAB> to get the ≈ symbolb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now benchmark the C code directly from Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_bench = @benchmark c_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"C\"] = minimum(c_bench.times) / 1e6  # in milliseconds\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Python's built in `sum`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PyCall` package provides a Julia interface to Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <built-in function sum>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000992326781932e6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pysum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pysum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  336 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     1.481 s (0.00% GC)\n",
       "  median time:      1.500 s (0.00% GC)\n",
       "  mean time:        1.499 s (0.00% GC)\n",
       "  maximum time:     1.514 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          4\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_list_bench = @benchmark $pysum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 3 entries:\n",
       "  \"Julia hand-written\" => 12.0256\n",
       "  \"Julia built-in\"     => 5.651\n",
       "  \"Python built-in\"    => 1481.04"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python built-in\"] = minimum(py_list_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Python: `numpy`\n",
    "\n",
    "`numpy` is an optimized C library, callable from Python.\n",
    "It may be installed within Julia as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conda.add(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  336 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     11.046 ms (0.00% GC)\n",
       "  median time:      11.650 ms (0.00% GC)\n",
       "  mean time:        11.786 ms (0.00% GC)\n",
       "  maximum time:     25.217 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          425\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum = pyimport(\"numpy\")[\"sum\"]\n",
    "\n",
    "py_numpy_bench = @benchmark $numpy_sum($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0009923267818885e6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_sum(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 4 entries:\n",
       "  \"Python numpy\"       => 11.0456\n",
       "  \"Julia hand-written\" => 12.0256\n",
       "  \"Julia built-in\"     => 5.651\n",
       "  \"Python built-in\"    => 1481.04"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python numpy\"] = minimum(py_numpy_bench.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Python, hand-written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function py_sum at 0x0000000002658DC0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py\"\"\"\n",
    "def py_sum(A):\n",
    "    s = 0.0\n",
    "    for a in A:\n",
    "        s += a\n",
    "    return s\n",
    "\"\"\"\n",
    "\n",
    "sum_py = py\"py_sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  336 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     2.093 s (0.00% GC)\n",
       "  median time:      2.151 s (0.00% GC)\n",
       "  mean time:        2.138 s (0.00% GC)\n",
       "  maximum time:     2.169 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          3\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_hand = @benchmark $sum_py($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000992326781932e6"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_py(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_py(a) ≈ sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 5 entries:\n",
       "  \"Python numpy\"        => 11.0456\n",
       "  \"Julia hand-written\"  => 12.0256\n",
       "  \"Python hand-written\" => 2093.13\n",
       "  \"Julia built-in\"      => 5.651\n",
       "  \"Python built-in\"     => 1481.04"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Python hand-written\"] = minimum(py_hand.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia built-in..............5.7\n",
      "Python numpy...............11.0\n",
      "Julia hand-written.........12.0\n",
      "Python built-in..........1481.0\n",
      "Python hand-written......2093.1\n"
     ]
    }
   ],
   "source": [
    "for (key, value) in sort(collect(d), by=last)\n",
    "    println(rpad(key, 25, \".\"), lpad(round(value; digits=1), 6, \".\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have three different performance classes here: The numpy and Julia\n",
    "builtins are leading the pack, followed by the hand-written Julia and C\n",
    "definitions. Those seem to be about 2x slower.  And then we have the much much\n",
    "slower Python definitions over 100x slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploiting parallelism with Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that our hand-written Julia solution was almost an even multiple of\n",
    "2x slower than the builtin solutions is a big clue: perhaps theres some sort\n",
    "of 2x parallelism going on here?\n",
    "\n",
    "(In fairness, there are ways to exploit parallelism in other languages, too,\n",
    "but for brevity we won't cover them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Julia (allowing floating point associativity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `for` loop\n",
    "\n",
    "```julia\n",
    "for a in A\n",
    "    s += a\n",
    "end\n",
    "```\n",
    "\n",
    "defines a very strict _order_ to the summation: Julia follows exactly what you\n",
    "wrote and adds the elements of `A` to the result `s` in the order it iterates.\n",
    "Since floating point numbers aren't associative, a rearrangement here would\n",
    "change the answer — and Julia is loathe to give you different answer than\n",
    "the one you asked for.\n",
    "\n",
    "You can, however, tell Julia to relax that rule and allow for associativity\n",
    "with the `@fastmath` macro. This might allow Julia to rearrange the sum in an\n",
    "advantageous manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum_fast (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum_fast(A)\n",
    "    s = 0.0\n",
    "    for a in A\n",
    "        @fastmath s += a\n",
    "    end\n",
    "    s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     5.159 ms (0.00% GC)\n",
       "  median time:      5.504 ms (0.00% GC)\n",
       "  mean time:        5.579 ms (0.00% GC)\n",
       "  maximum time:     12.262 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          896\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_bench_hand_fast = @benchmark mysum_fast($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.000992326781954e6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysum_fast(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 6 entries:\n",
       "  \"Python numpy\"            => 11.0456\n",
       "  \"Julia hand-written\"      => 12.0256\n",
       "  \"Python hand-written\"     => 2093.13\n",
       "  \"Julia built-in\"          => 5.651\n",
       "  \"Python built-in\"         => 1481.04\n",
       "  \"Julia hand-written fast\" => 5.1591"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Julia hand-written fast\"] = minimum(j_bench_hand_fast.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Distributed Julia (built-in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take this one step further: nearly every modern computer these days has\n",
    "multiple cores. All the above solutions are working one core hard, but all the\n",
    "others are just sitting by idly. Let's put them to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `C:\\Users\\sousa\\.julia\\registries\\General`\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `C:\\Users\\sousa\\.julia\\registries\\JuliaComputingRegistry`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `C:\\Users\\sousa\\.julia\\environments\\v1.5\\Project.toml`\n",
      " \u001b[90m [aaf54ef3] \u001b[39m\u001b[92m+ DistributedArrays v0.6.5\u001b[39m\n",
      "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `C:\\Users\\sousa\\.julia\\environments\\v1.5\\Manifest.toml`\n",
      " \u001b[90m [aaf54ef3] \u001b[39m\u001b[92m+ DistributedArrays v0.6.5\u001b[39m\n",
      " \u001b[90m [27ebfcd6] \u001b[39m\u001b[92m+ Primes v0.4.0\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(\"DistributedArrays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling DistributedArrays [aaf54ef3-cdf8-58ed-94cc-d582ad619b94]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    }
   ],
   "source": [
    "using Distributed\n",
    "using DistributedArrays\n",
    "addprocs(4)\n",
    "@sync @everywhere workers() include(\"/opt/julia-1.0/etc/julia/startup.jl\") # Needed just for JuliaBox\n",
    "@everywhere using DistributedArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adist = distribute(a)\n",
    "j_bench_dist = @benchmark sum($adist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Julia 4x built-in\"] = minimum(j_bench_dist.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Distributed Julia (hand-written)\n",
    "\n",
    "Ok, that might be cheating, too — it's again just calling a library\n",
    "function. Is it possible to write distributed sum ourselves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mysum_dist(a::DArray)\n",
    "    r = Array{Future}(undef, length(procs(a)))\n",
    "    for (i, id) in enumerate(procs(a))\n",
    "        r[i] = @spawnat id sum(localpart(a))\n",
    "    end\n",
    "    return sum(fetch.(r))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_bench_hand_dist = @benchmark mysum_dist($adist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Julia 4x hand-written\"] = minimum(j_bench_hand_dist.times) / 1e6\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (key, value) in sort(collect(d), by=last)\n",
    "    println(rpad(key, 25, \".\"), lpad(round(value; digits=1), 6, \".\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key take-aways\n",
    "\n",
    "* Julia allows for serial C-like performance, even with hand-written functions\n",
    "* Julia allows us to exploit many forms of parallelism to further improve performance. We demonstrated:\n",
    "    * Single-processor parallelism with SIMD\n",
    "    * Multi-process parallelism with DistributedArrays\n",
    "* But there are many other ways to express parallelism, too!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
