{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMD: The parallelism that can (sometimes) happen automatically\n",
    "\n",
    "SIMD: Single-instruction, multiple data\n",
    "\n",
    "(Also confusingly called vectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The architecture\n",
    "\n",
    "Instead of computing four sums sequentially:\n",
    "\n",
    "\\begin{align}\n",
    "x_1 + y_1 &\\rightarrow z_1 \\\\\n",
    "x_2 + y_2 &\\rightarrow z_2 \\\\\n",
    "x_3 + y_3 &\\rightarrow z_3 \\\\\n",
    "x_4 + y_4 &\\rightarrow z_4\n",
    "\\end{align}\n",
    "\n",
    "Modern processors have vector processing units that can do it all at once:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{cc}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "x_4\n",
    "\\end{array}\\right)\n",
    "+\n",
    "\\left(\\begin{array}{cc}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3 \\\\\n",
    "y_4\n",
    "\\end{array}\\right)\n",
    "\\rightarrow\n",
    "\\left(\\begin{array}{cc}\n",
    "z_1 \\\\\n",
    "z_2 \\\\\n",
    "z_3 \\\\\n",
    "z_4\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making it happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple task: compute the sum of a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50007.23271152478"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(100_000)\n",
    "\n",
    "function simplesum(A)\n",
    "    result = zero(eltype(A))\n",
    "    for i in eachindex(A)\n",
    "        @inbounds result += A[i]\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "\n",
    "simplesum(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  114.499 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50007.23271152478"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@btime simplesum($A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, is that good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14.499 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50007.23271152423"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime sum($A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're slower that the builtin `sum` — and we're getting a different answer, too! Let's look at what happens with a 32-bit float instead of a 64 bit one. Each element has half the number of bits, so lets also double the length (so the total number of bits processed remains constant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  229.099 μs (0 allocations: 0 bytes)\n",
      "  16.199 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "A32 = rand(Float32, length(A)*2)\n",
    "\n",
    "@btime simplesum($A32)\n",
    "@btime sum($A32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's even worse! What's going on here?  We're seeing an even multiple number\n",
    "difference in our performance — perhaps Julia's builtin sum is using some\n",
    "parallelism? Let's try using SIMD ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  13.399 μs (0 allocations: 0 bytes)\n",
      "  13.399 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100001.39f0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function simdsum(A)\n",
    "    result = zero(eltype(A))\n",
    "    @simd for i in eachindex(A)\n",
    "        @inbounds result += A[i]\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "\n",
    "@btime simdsum($A)\n",
    "@btime simdsum($A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did that do and why don't we always use `@simd for` — or why doesn't Julia\n",
    "just always use `@simd` for every `for` loop automatically?  Look at the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50007.23271152478, 50007.2327115242, 50007.23271152423)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplesum(A), simdsum(A), sum(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100001.9f0, 100001.39f0, 100001.41f0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplesum(A32), simdsum(A32), sum(A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why aren't they the same?\n",
    "\n",
    "Without `@simd`, Julia is doing _exactly_ what we told it to do: it's taking\n",
    "each element of our array and adding it to a big pile sequentially. Our answer\n",
    "is smaller than what Julia's builtin `sum` thinks it is: that's because as our\n",
    "pile gets bigger we begin losing the lower bits of each element that we're\n",
    "adding, and those small losses begin to add up!\n",
    "\n",
    "The `@simd` macro tells Julia that it can re-arrange floating point additions —\n",
    "even if it would change the answer. Depending on your CPU, this may lead to 2x or 4x\n",
    "or even 8x parallelism. Essentially, Julia is computing independent sums for\n",
    "the even indices and the odd indices simultaneously:\n",
    "\n",
    "\\begin{align}\n",
    "odds &\\leftarrow 0 \\\\\n",
    "evens &\\leftarrow 0 \\\\\n",
    "\\text{loop}&\\ \\text{odd}\\ i: \\\\\n",
    "    &\\left(\\begin{array}{cc}\n",
    "odds \\\\\n",
    "evens\n",
    "\\end{array}\\right)\n",
    "\\leftarrow\n",
    "\\left(\\begin{array}{cc}\n",
    "odds \\\\\n",
    "evens\n",
    "\\end{array}\\right)\n",
    "+\n",
    "\\left(\\begin{array}{cc}\n",
    "x_{i} \\\\\n",
    "x_{i+1}\n",
    "\\end{array}\\right) \\\\\n",
    "total &\\leftarrow evens + odds\n",
    "\\end{align}\n",
    "\n",
    "In many cases, Julia can and does know that a for-loop can be SIMD-ed and it\n",
    "will take advantage of this by default!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  13.399 μs (0 allocations: 0 bytes)\n",
      "  14.099 μs (0 allocations: 0 bytes)\n",
      "  13.399 μs (0 allocations: 0 bytes)\n",
      "  13.399 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1102157"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = rand(1:10, 100_000)\n",
    "\n",
    "@btime simplesum($B)\n",
    "@btime sum($B)\n",
    "\n",
    "B32 = rand(Int32(1):Int32(10), length(B)*2)\n",
    "\n",
    "@btime simplesum($B32)\n",
    "@btime simdsum($B32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we see if something is getting vectorized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ";  @ In[5]:1 within `simdsum'\n",
      "; Function Attrs: uwtable\n",
      "define float @julia_simdsum_1490(%jl_value_t* nonnull align 16 dereferenceable(40)) #0 {\n",
      "top:\n",
      ";  @ In[5]:3 within `simdsum'\n",
      "; ┌ @ simdloop.jl:69 within `macro expansion'\n",
      "; │┌ @ abstractarray.jl:212 within `eachindex'\n",
      "; ││┌ @ abstractarray.jl:95 within `axes1'\n",
      "; │││┌ @ abstractarray.jl:75 within `axes'\n",
      "; ││││┌ @ array.jl:155 within `size'\n",
      "       %1 = bitcast %jl_value_t* %0 to %jl_value_t**\n",
      "       %2 = getelementptr inbounds %jl_value_t*, %jl_value_t** %1, i64 3\n",
      "       %3 = bitcast %jl_value_t** %2 to i64*\n",
      "       %4 = load i64, i64* %3, align 8\n",
      "; ││││└\n",
      "; ││││┌ @ tuple.jl:157 within `map'\n",
      "; │││││┌ @ range.jl:326 within `OneTo' @ range.jl:317\n",
      "; ││││││┌ @ promotion.jl:409 within `max'\n",
      "         %5 = icmp sgt i64 %4, 0\n",
      "         %6 = select i1 %5, i64 %4, i64 0\n",
      "; │└└└└└└\n",
      "; │ @ simdloop.jl:72 within `macro expansion'\n",
      "   br i1 %5, label %L13.lr.ph, label %L30\n",
      "\n",
      "L13.lr.ph:                                        ; preds = %top\n",
      "; │ @ simdloop.jl:77 within `macro expansion' @ In[5]:4\n",
      "; │┌ @ array.jl within `getindex'\n",
      "    %7 = bitcast %jl_value_t* %0 to float**\n",
      "    %8 = load float*, float** %7, align 8\n",
      "; │└\n",
      "; │ @ simdloop.jl:75 within `macro expansion'\n",
      "   %min.iters.check = icmp ult i64 %6, 32\n",
      "   br i1 %min.iters.check, label %scalar.ph, label %vector.ph\n",
      "\n",
      "vector.ph:                                        ; preds = %L13.lr.ph\n",
      "   %n.mod.vf = urem i64 %6, 32\n",
      "   %n.vec = sub i64 %6, %n.mod.vf\n",
      "   br label %vector.body\n",
      "\n",
      "vector.body:                                      ; preds = %vector.body, %vector.ph\n",
      "; │ @ simdloop.jl:78 within `macro expansion'\n",
      "; │┌ @ int.jl:86 within `+'\n",
      "    %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]\n",
      "    %vec.phi = phi <8 x float> [ zeroinitializer, %vector.ph ], [ %19, %vector.body ]\n",
      "    %vec.phi10 = phi <8 x float> [ zeroinitializer, %vector.ph ], [ %20, %vector.body ]\n",
      "    %vec.phi11 = phi <8 x float> [ zeroinitializer, %vector.ph ], [ %21, %vector.body ]\n",
      "    %vec.phi12 = phi <8 x float> [ zeroinitializer, %vector.ph ], [ %22, %vector.body ]\n",
      "    %9 = add i64 %index, 0\n",
      "; │└\n",
      "; │ @ simdloop.jl:77 within `macro expansion' @ In[5]:4\n",
      "; │┌ @ array.jl:809 within `getindex'\n",
      "    %10 = getelementptr inbounds float, float* %8, i64 %9\n",
      "    %11 = getelementptr inbounds float, float* %10, i32 0\n",
      "    %12 = bitcast float* %11 to <8 x float>*\n",
      "    %wide.load = load <8 x float>, <8 x float>* %12, align 4\n",
      "    %13 = getelementptr inbounds float, float* %10, i32 8\n",
      "    %14 = bitcast float* %13 to <8 x float>*\n",
      "    %wide.load13 = load <8 x float>, <8 x float>* %14, align 4\n",
      "    %15 = getelementptr inbounds float, float* %10, i32 16\n",
      "    %16 = bitcast float* %15 to <8 x float>*\n",
      "    %wide.load14 = load <8 x float>, <8 x float>* %16, align 4\n",
      "    %17 = getelementptr inbounds float, float* %10, i32 24\n",
      "    %18 = bitcast float* %17 to <8 x float>*\n",
      "    %wide.load15 = load <8 x float>, <8 x float>* %18, align 4\n",
      "; │└\n",
      "; │┌ @ float.jl:400 within `+'\n",
      "    %19 = fadd fast <8 x float> %vec.phi, %wide.load\n",
      "    %20 = fadd fast <8 x float> %vec.phi10, %wide.load13\n",
      "    %21 = fadd fast <8 x float> %vec.phi11, %wide.load14\n",
      "    %22 = fadd fast <8 x float> %vec.phi12, %wide.load15\n",
      "; │└\n",
      "; │ @ simdloop.jl:78 within `macro expansion'\n",
      "; │┌ @ int.jl:86 within `+'\n",
      "    %index.next = add i64 %index, 32\n",
      "    %23 = icmp eq i64 %index.next, %n.vec\n",
      "    br i1 %23, label %middle.block, label %vector.body\n",
      "\n",
      "middle.block:                                     ; preds = %vector.body\n",
      "; │└\n",
      "; │ @ simdloop.jl:75 within `macro expansion'\n",
      "   %bin.rdx = fadd fast <8 x float> %20, %19\n",
      "   %bin.rdx16 = fadd fast <8 x float> %21, %bin.rdx\n",
      "   %bin.rdx17 = fadd fast <8 x float> %22, %bin.rdx16\n",
      "   %rdx.shuf = shufflevector <8 x float> %bin.rdx17, <8 x float> undef, <8 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef>\n",
      "   %bin.rdx18 = fadd fast <8 x float> %bin.rdx17, %rdx.shuf\n",
      "   %rdx.shuf19 = shufflevector <8 x float> %bin.rdx18, <8 x float> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>\n",
      "   %bin.rdx20 = fadd fast <8 x float> %bin.rdx18, %rdx.shuf19\n",
      "   %rdx.shuf21 = shufflevector <8 x float> %bin.rdx20, <8 x float> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>\n",
      "   %bin.rdx22 = fadd fast <8 x float> %bin.rdx20, %rdx.shuf21\n",
      "   %24 = extractelement <8 x float> %bin.rdx22, i32 0\n",
      "   %cmp.n = icmp eq i64 %6, %n.vec\n",
      "   br i1 %cmp.n, label %L30, label %scalar.ph\n",
      "\n",
      "scalar.ph:                                        ; preds = %middle.block, %L13.lr.ph\n",
      "   %bc.resume.val = phi i64 [ %n.vec, %middle.block ], [ 0, %L13.lr.ph ]\n",
      "   %bc.merge.rdx = phi float [ 0.000000e+00, %L13.lr.ph ], [ %24, %middle.block ]\n",
      "   br label %L13\n",
      "\n",
      "L13:                                              ; preds = %L13, %scalar.ph\n",
      "   %value_phi16 = phi i64 [ %bc.resume.val, %scalar.ph ], [ %28, %L13 ]\n",
      "   %value_phi5 = phi float [ %bc.merge.rdx, %scalar.ph ], [ %27, %L13 ]\n",
      "; │ @ simdloop.jl:77 within `macro expansion' @ In[5]:4\n",
      "; │┌ @ array.jl:809 within `getindex'\n",
      "    %25 = getelementptr inbounds float, float* %8, i64 %value_phi16\n",
      "    %26 = load float, float* %25, align 4\n",
      "; │└\n",
      "; │┌ @ float.jl:400 within `+'\n",
      "    %27 = fadd fast float %value_phi5, %26\n",
      "; │└\n",
      "; │ @ simdloop.jl:78 within `macro expansion'\n",
      "; │┌ @ int.jl:86 within `+'\n",
      "    %28 = add nuw nsw i64 %value_phi16, 1\n",
      "; │└\n",
      "; │ @ simdloop.jl:75 within `macro expansion'\n",
      "; │┌ @ int.jl:82 within `<'\n",
      "    %29 = icmp ult i64 %28, %6\n",
      "; │└\n",
      "   br i1 %29, label %L13, label %L30\n",
      "\n",
      "L30:                                              ; preds = %L13, %middle.block, %top\n",
      "   %value_phi2 = phi float [ 0.000000e+00, %top ], [ %24, %middle.block ], [ %27, %L13 ]\n",
      "; └\n",
      ";  @ In[5]:6 within `simdsum'\n",
      "  ret float %value_phi2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@code_llvm simdsum(A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what are the challenges?\n",
    "\n",
    "* Biggest hurdle is that you have to convince Julia and LLVM that it's able to\n",
    "  use SIMD instructions for your given algorithm. That's not always possible.\n",
    "* There are lots of limitations of what can and cannot be SIMD-ed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "@simd\n",
       "\\end{verbatim}\n",
       "Annotate a \\texttt{for} loop to allow the compiler to take extra liberties to allow loop re-ordering\n",
       "\n",
       "\\begin{quote}\n",
       "\\textbf{warning}\n",
       "\n",
       "Warning\n",
       "\n",
       "This feature is experimental and could change or disappear in future versions of Julia. Incorrect use of the \\texttt{@simd} macro may cause unexpected results.\n",
       "\n",
       "\\end{quote}\n",
       "The object iterated over in a \\texttt{@simd for} loop should be a one-dimensional range. By using \\texttt{@simd}, you are asserting several properties of the loop:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item It is safe to execute iterations in arbitrary or overlapping order, with special consideration for reduction variables.\n",
       "\n",
       "\n",
       "\\item Floating-point operations on reduction variables can be reordered, possibly causing different results than without \\texttt{@simd}.\n",
       "\n",
       "\\end{itemize}\n",
       "In many cases, Julia is able to automatically vectorize inner for loops without the use of \\texttt{@simd}. Using \\texttt{@simd} gives the compiler a little extra leeway to make it possible in more situations. In either case, your inner loop should have the following properties to allow vectorization:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item The loop must be an innermost loop\n",
       "\n",
       "\n",
       "\\item The loop body must be straight-line code. Therefore, \\href{@ref}{\\texttt{@inbounds}} is   currently needed for all array accesses. The compiler can sometimes turn   short \\texttt{\\&\\&}, \\texttt{||}, and \\texttt{?:} expressions into straight-line code if it is safe   to evaluate all operands unconditionally. Consider using the \\href{@ref}{\\texttt{ifelse}}   function instead of \\texttt{?:} in the loop if it is safe to do so.\n",
       "\n",
       "\n",
       "\\item Accesses must have a stride pattern and cannot be \"gathers\" (random-index   reads) or \"scatters\" (random-index writes).\n",
       "\n",
       "\n",
       "\\item The stride should be unit stride.\n",
       "\n",
       "\\end{itemize}\n",
       "\\begin{quote}\n",
       "\\textbf{note}\n",
       "\n",
       "Note\n",
       "\n",
       "The \\texttt{@simd} does not assert by default that the loop is completely free of loop-carried memory dependencies, which is an assumption that can easily be violated in generic code. If you are writing non-generic code, you can use \\texttt{@simd ivdep for ... end} to also assert that:\n",
       "\n",
       "\\end{quote}\n",
       "\\begin{itemize}\n",
       "\\item There exists no loop-carried memory dependencies\n",
       "\n",
       "\n",
       "\\item No iteration ever waits on a previous iteration to make forward progress.\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "```\n",
       "@simd\n",
       "```\n",
       "\n",
       "Annotate a `for` loop to allow the compiler to take extra liberties to allow loop re-ordering\n",
       "\n",
       "!!! warning\n",
       "    This feature is experimental and could change or disappear in future versions of Julia. Incorrect use of the `@simd` macro may cause unexpected results.\n",
       "\n",
       "\n",
       "The object iterated over in a `@simd for` loop should be a one-dimensional range. By using `@simd`, you are asserting several properties of the loop:\n",
       "\n",
       "  * It is safe to execute iterations in arbitrary or overlapping order, with special consideration for reduction variables.\n",
       "  * Floating-point operations on reduction variables can be reordered, possibly causing different results than without `@simd`.\n",
       "\n",
       "In many cases, Julia is able to automatically vectorize inner for loops without the use of `@simd`. Using `@simd` gives the compiler a little extra leeway to make it possible in more situations. In either case, your inner loop should have the following properties to allow vectorization:\n",
       "\n",
       "  * The loop must be an innermost loop\n",
       "  * The loop body must be straight-line code. Therefore, [`@inbounds`](@ref) is   currently needed for all array accesses. The compiler can sometimes turn   short `&&`, `||`, and `?:` expressions into straight-line code if it is safe   to evaluate all operands unconditionally. Consider using the [`ifelse`](@ref)   function instead of `?:` in the loop if it is safe to do so.\n",
       "  * Accesses must have a stride pattern and cannot be \"gathers\" (random-index   reads) or \"scatters\" (random-index writes).\n",
       "  * The stride should be unit stride.\n",
       "\n",
       "!!! note\n",
       "    The `@simd` does not assert by default that the loop is completely free of loop-carried memory dependencies, which is an assumption that can easily be violated in generic code. If you are writing non-generic code, you can use `@simd ivdep for ... end` to also assert that:\n",
       "\n",
       "\n",
       "  * There exists no loop-carried memory dependencies\n",
       "  * No iteration ever waits on a previous iteration to make forward progress.\n"
      ],
      "text/plain": [
       "\u001b[36m  @simd\u001b[39m\n",
       "\n",
       "  Annotate a \u001b[36mfor\u001b[39m loop to allow the compiler to take extra liberties to allow\n",
       "  loop re-ordering\n",
       "\n",
       "\u001b[33m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning\u001b[22m\u001b[39m\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  This feature is experimental and could change or disappear in\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  future versions of Julia. Incorrect use of the \u001b[36m@simd\u001b[39m macro may\n",
       "\u001b[33m\u001b[1m  │\u001b[22m\u001b[39m  cause unexpected results.\n",
       "\n",
       "  The object iterated over in a \u001b[36m@simd for\u001b[39m loop should be a one-dimensional\n",
       "  range. By using \u001b[36m@simd\u001b[39m, you are asserting several properties of the loop:\n",
       "\n",
       "    •    It is safe to execute iterations in arbitrary or overlapping\n",
       "        order, with special consideration for reduction variables.\n",
       "\n",
       "    •    Floating-point operations on reduction variables can be reordered,\n",
       "        possibly causing different results than without \u001b[36m@simd\u001b[39m.\n",
       "\n",
       "  In many cases, Julia is able to automatically vectorize inner for loops\n",
       "  without the use of \u001b[36m@simd\u001b[39m. Using \u001b[36m@simd\u001b[39m gives the compiler a little extra\n",
       "  leeway to make it possible in more situations. In either case, your inner\n",
       "  loop should have the following properties to allow vectorization:\n",
       "\n",
       "    •    The loop must be an innermost loop\n",
       "\n",
       "    •    The loop body must be straight-line code. Therefore, \u001b[36m@inbounds\u001b[39m is\n",
       "        currently needed for all array accesses. The compiler can\n",
       "        sometimes turn short \u001b[36m&&\u001b[39m, \u001b[36m||\u001b[39m, and \u001b[36m?:\u001b[39m expressions into straight-line\n",
       "        code if it is safe to evaluate all operands unconditionally.\n",
       "        Consider using the \u001b[36mifelse\u001b[39m function instead of \u001b[36m?:\u001b[39m in the loop if it\n",
       "        is safe to do so.\n",
       "\n",
       "    •    Accesses must have a stride pattern and cannot be \"gathers\"\n",
       "        (random-index reads) or \"scatters\" (random-index writes).\n",
       "\n",
       "    •    The stride should be unit stride.\n",
       "\n",
       "\u001b[36m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[36m\u001b[1mNote\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  The \u001b[36m@simd\u001b[39m does not assert by default that the loop is completely\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  free of loop-carried memory dependencies, which is an assumption\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  that can easily be violated in generic code. If you are writing\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  non-generic code, you can use \u001b[36m@simd ivdep for ... end\u001b[39m to also\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  assert that:\n",
       "\n",
       "    •    There exists no loop-carried memory dependencies\n",
       "\n",
       "    •    No iteration ever waits on a previous iteration to make forward\n",
       "        progress."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc @simd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You do need to think through the consequences of re-ordering your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A slightly trickier case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function diff!(A, B)\n",
    "    A[1] = B[1]\n",
    "    for i in 2:length(A)\n",
    "        @inbounds A[i] = B[i] - B[i-1]\n",
    "    end\n",
    "    return A\n",
    "end\n",
    "A = zeros(Float32, 100_000)\n",
    "B = rand(Float32, 100_000)\n",
    "\n",
    "diff!(A, B)\n",
    "[B[1];diff(B)] == A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  17.299 μs (0 allocations: 0 bytes)\n",
      "  33.400 μs (2 allocations: 390.70 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime diff!($A, $B)\n",
    "@btime diff($B);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what happens if we do it in-place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  257.799 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "Bcopy = copy(B)\n",
    "@btime diff!($Bcopy, $Bcopy);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ";  @ In[12]:1 within `diff!'\n",
      "; Function Attrs: uwtable\n",
      "define nonnull %jl_value_t* @\"japi1_diff!_1838\"(%jl_value_t*, %jl_value_t**, i32) #0 {\n",
      "top:\n",
      "  %3 = alloca %jl_value_t**, align 8\n",
      "  store volatile %jl_value_t** %1, %jl_value_t*** %3, align 8\n",
      "  %4 = load %jl_value_t*, %jl_value_t** %1, align 8\n",
      "  %5 = getelementptr inbounds %jl_value_t*, %jl_value_t** %1, i64 1\n",
      "  %6 = load %jl_value_t*, %jl_value_t** %5, align 8\n",
      ";  @ In[12]:2 within `diff!'\n",
      "; ┌ @ array.jl:809 within `getindex'\n",
      "   %7 = bitcast %jl_value_t* %6 to %jl_array_t*\n",
      "   %8 = getelementptr inbounds %jl_array_t, %jl_array_t* %7, i64 0, i32 1\n",
      "   %9 = load i64, i64* %8, align 8\n",
      "   %10 = icmp eq i64 %9, 0\n",
      "   br i1 %10, label %oob, label %idxend\n",
      "\n",
      "L15:                                              ; preds = %scalar.ph, %L15\n",
      "   %value_phi5 = phi i64 [ %23, %L15 ], [ %bc.resume.val, %scalar.ph ]\n",
      "; └\n",
      ";  @ In[12]:4 within `diff!'\n",
      "; ┌ @ array.jl:809 within `getindex'\n",
      "   %11 = add i64 %value_phi5, -1\n",
      "   %12 = getelementptr inbounds i32, i32* %31, i64 %11\n",
      "   %13 = bitcast i32* %12 to float*\n",
      "   %14 = load float, float* %13, align 4\n",
      "   %15 = add i64 %value_phi5, -2\n",
      "   %16 = getelementptr inbounds i32, i32* %31, i64 %15\n",
      "   %17 = bitcast i32* %16 to float*\n",
      "   %18 = load float, float* %17, align 4\n",
      "; └\n",
      "; ┌ @ float.jl:402 within `-'\n",
      "   %19 = fsub float %14, %18\n",
      "; └\n",
      "; ┌ @ array.jl:847 within `setindex!'\n",
      "   %20 = getelementptr inbounds i32, i32* %35, i64 %11\n",
      "   %21 = bitcast i32* %20 to float*\n",
      "   store float %19, float* %21, align 4\n",
      "; └\n",
      "; ┌ @ range.jl:624 within `iterate'\n",
      "; │┌ @ promotion.jl:398 within `=='\n",
      "    %22 = icmp eq i64 %value_phi5, %37\n",
      "; │└\n",
      "   %23 = add i64 %value_phi5, 1\n",
      "; └\n",
      "  br i1 %22, label %L33, label %L15\n",
      "\n",
      "L33:                                              ; preds = %middle.block, %idxend2, %L15\n",
      ";  @ In[12]:6 within `diff!'\n",
      "  ret %jl_value_t* %4\n",
      "\n",
      "oob:                                              ; preds = %top\n",
      ";  @ In[12]:2 within `diff!'\n",
      "; ┌ @ array.jl:809 within `getindex'\n",
      "   %24 = alloca i64, align 8\n",
      "   store i64 1, i64* %24, align 8\n",
      "   call void @jl_bounds_error_ints(%jl_value_t* %6, i64* nonnull %24, i64 1)\n",
      "   unreachable\n",
      "\n",
      "idxend:                                           ; preds = %top\n",
      "; └\n",
      "; ┌ @ array.jl:847 within `setindex!'\n",
      "   %25 = bitcast %jl_value_t* %4 to %jl_array_t*\n",
      "   %26 = getelementptr inbounds %jl_array_t, %jl_array_t* %25, i64 0, i32 1\n",
      "   %27 = load i64, i64* %26, align 8\n",
      "   %28 = icmp eq i64 %27, 0\n",
      "   br i1 %28, label %oob1, label %idxend2\n",
      "\n",
      "oob1:                                             ; preds = %idxend\n",
      "   %29 = alloca i64, align 8\n",
      "   store i64 1, i64* %29, align 8\n",
      "   call void @jl_bounds_error_ints(%jl_value_t* %4, i64* nonnull %29, i64 1)\n",
      "   unreachable\n",
      "\n",
      "idxend2:                                          ; preds = %idxend\n",
      "; └\n",
      "; ┌ @ array.jl:809 within `getindex'\n",
      "   %30 = bitcast %jl_value_t* %6 to i32**\n",
      "   %31 = load i32*, i32** %30, align 8\n",
      "   %32 = bitcast i32* %31 to i8*\n",
      "   %33 = load i32, i32* %31, align 4\n",
      "; └\n",
      "; ┌ @ array.jl:847 within `setindex!'\n",
      "   %34 = bitcast %jl_value_t* %4 to i32**\n",
      "   %35 = load i32*, i32** %34, align 8\n",
      "   store i32 %33, i32* %35, align 4\n",
      "; └\n",
      ";  @ In[12]:3 within `diff!'\n",
      "; ┌ @ range.jl:5 within `Colon'\n",
      "; │┌ @ range.jl:280 within `UnitRange'\n",
      "; ││┌ @ range.jl:285 within `unitrange_last'\n",
      "; │││┌ @ operators.jl:350 within `>='\n",
      "; ││││┌ @ int.jl:441 within `<='\n",
      "       %36 = icmp sgt i64 %27, 1\n",
      "; │││└└\n",
      "     %37 = select i1 %36, i64 %27, i64 1\n",
      "; └└└\n",
      "  br i1 %36, label %L15.preheader, label %L33\n",
      "\n",
      "L15.preheader:                                    ; preds = %idxend2\n",
      ";  @ In[12]:4 within `diff!'\n",
      "  %38 = add i64 %37, -1\n",
      "  %min.iters.check = icmp ult i64 %38, 32\n",
      "  br i1 %min.iters.check, label %scalar.ph, label %vector.memcheck\n",
      "\n",
      "vector.memcheck:                                  ; preds = %L15.preheader\n",
      "  %scevgep = getelementptr i32, i32* %35, i64 1\n",
      "  %scevgep10 = bitcast i32* %scevgep to i8*\n",
      "  %scevgep11 = getelementptr i32, i32* %35, i64 %37\n",
      "  %scevgep1112 = bitcast i32* %scevgep11 to i8*\n",
      "  %scevgep13 = getelementptr i32, i32* %31, i64 %37\n",
      "  %scevgep1314 = bitcast i32* %scevgep13 to i8*\n",
      "  %bound0 = icmp ult i8* %scevgep10, %scevgep1314\n",
      "  %bound1 = icmp ult i8* %32, %scevgep1112\n",
      "  %found.conflict = and i1 %bound0, %bound1\n",
      "  %memcheck.conflict = and i1 %found.conflict, true\n",
      "  br i1 %memcheck.conflict, label %scalar.ph, label %vector.ph\n",
      "\n",
      "vector.ph:                                        ; preds = %vector.memcheck\n",
      "  %n.mod.vf = urem i64 %38, 32\n",
      "  %n.vec = sub i64 %38, %n.mod.vf\n",
      "  %ind.end = add i64 2, %n.vec\n",
      "  br label %vector.body\n",
      "\n",
      "vector.body:                                      ; preds = %vector.body, %vector.ph\n",
      "  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]\n",
      "  %offset.idx = add i64 2, %index\n",
      "  %39 = add i64 %offset.idx, 0\n",
      "; ┌ @ array.jl:809 within `getindex'\n",
      "   %40 = add i64 %39, -1\n",
      "   %41 = getelementptr inbounds i32, i32* %31, i64 %40\n",
      "   %42 = bitcast i32* %41 to float*\n",
      "   %43 = getelementptr inbounds float, float* %42, i32 0\n",
      "   %44 = bitcast float* %43 to <8 x float>*\n",
      "   %wide.load = load <8 x float>, <8 x float>* %44, align 4\n",
      "   %45 = getelementptr inbounds float, float* %42, i32 8\n",
      "   %46 = bitcast float* %45 to <8 x float>*\n",
      "   %wide.load18 = load <8 x float>, <8 x float>* %46, align 4\n",
      "   %47 = getelementptr inbounds float, float* %42, i32 16\n",
      "   %48 = bitcast float* %47 to <8 x float>*\n",
      "   %wide.load19 = load <8 x float>, <8 x float>* %48, align 4\n",
      "   %49 = getelementptr inbounds float, float* %42, i32 24\n",
      "   %50 = bitcast float* %49 to <8 x float>*\n",
      "   %wide.load20 = load <8 x float>, <8 x float>* %50, align 4\n",
      "   %51 = add i64 %39, -2\n",
      "   %52 = getelementptr inbounds i32, i32* %31, i64 %51\n",
      "   %53 = bitcast i32* %52 to float*\n",
      "   %54 = getelementptr inbounds float, float* %53, i32 0\n",
      "   %55 = bitcast float* %54 to <8 x float>*\n",
      "   %wide.load21 = load <8 x float>, <8 x float>* %55, align 4\n",
      "   %56 = getelementptr inbounds float, float* %53, i32 8\n",
      "   %57 = bitcast float* %56 to <8 x float>*\n",
      "   %wide.load22 = load <8 x float>, <8 x float>* %57, align 4\n",
      "   %58 = getelementptr inbounds float, float* %53, i32 16\n",
      "   %59 = bitcast float* %58 to <8 x float>*\n",
      "   %wide.load23 = load <8 x float>, <8 x float>* %59, align 4\n",
      "   %60 = getelementptr inbounds float, float* %53, i32 24\n",
      "   %61 = bitcast float* %60 to <8 x float>*\n",
      "   %wide.load24 = load <8 x float>, <8 x float>* %61, align 4\n",
      "; └\n",
      "; ┌ @ float.jl:402 within `-'\n",
      "   %62 = fsub <8 x float> %wide.load, %wide.load21\n",
      "   %63 = fsub <8 x float> %wide.load18, %wide.load22\n",
      "   %64 = fsub <8 x float> %wide.load19, %wide.load23\n",
      "   %65 = fsub <8 x float> %wide.load20, %wide.load24\n",
      "; └\n",
      "; ┌ @ array.jl:847 within `setindex!'\n",
      "   %66 = getelementptr inbounds i32, i32* %35, i64 %40\n",
      "   %67 = bitcast i32* %66 to float*\n",
      "   %68 = getelementptr inbounds float, float* %67, i32 0\n",
      "   %69 = bitcast float* %68 to <8 x float>*\n",
      "   store <8 x float> %62, <8 x float>* %69, align 4\n",
      "   %70 = getelementptr inbounds float, float* %67, i32 8\n",
      "   %71 = bitcast float* %70 to <8 x float>*\n",
      "   store <8 x float> %63, <8 x float>* %71, align 4\n",
      "   %72 = getelementptr inbounds float, float* %67, i32 16\n",
      "   %73 = bitcast float* %72 to <8 x float>*\n",
      "   store <8 x float> %64, <8 x float>* %73, align 4\n",
      "   %74 = getelementptr inbounds float, float* %67, i32 24\n",
      "   %75 = bitcast float* %74 to <8 x float>*\n",
      "   store <8 x float> %65, <8 x float>* %75, align 4\n",
      "   %index.next = add i64 %index, 32\n",
      "   %76 = icmp eq i64 %index.next, %n.vec\n",
      "   br i1 %76, label %middle.block, label %vector.body\n",
      "\n",
      "middle.block:                                     ; preds = %vector.body\n",
      "; └\n",
      "  %cmp.n = icmp eq i64 %38, %n.vec\n",
      "  br i1 %cmp.n, label %L33, label %scalar.ph\n",
      "\n",
      "scalar.ph:                                        ; preds = %middle.block, %vector.memcheck, %L15.preheader\n",
      "  %bc.resume.val = phi i64 [ %ind.end, %middle.block ], [ 2, %L15.preheader ], [ 2, %vector.memcheck ]\n",
      "  br label %L15\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "@code_llvm diff!(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manually assert that arrays don't alias (or have any loop-dependencies),\n",
    "with the very special `@simd ivdep` flag, but this can be disastrous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  16.899 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function unsafe_diff!(A, B)\n",
    "    A[1] = B[1]\n",
    "    @simd ivdep for i in 2:length(A)\n",
    "        @inbounds A[i] = B[i] - B[i-1]\n",
    "    end\n",
    "    return A\n",
    "end\n",
    "\n",
    "@btime unsafe_diff!($A, $B)\n",
    "[B[1];diff(B)] == A\n",
    "Bcopy = copy(B)\n",
    "unsafe_diff!(Bcopy, Bcopy)\n",
    "[B[1];diff(B)] == Bcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you really want to get your hands dirty, you can use the [SIMD.jl](https://github.com/eschnett/SIMD.jl)\n",
    "package to manually specify those `<8 x float>` things that LLVM generates.\n",
    "BUT: this is tricky and a pain; often it's just to be aware of what makes\n",
    "Julia code automatically SIMD-able, some of the cases where it may fail, and\n",
    "how to check its work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMD\n",
    "\n",
    "* Exploits built-in parallelism in a processor\n",
    "* Best for small, tight innermost loops\n",
    "* Often happens automatically if you're careful\n",
    "    * Follow the [perforance best practices](https://docs.julialang.org/en/v1/manual/performance-tips/)\n",
    "    * `@inbounds` any array acesses\n",
    "    * No branches or (non-inlined) function calls\n",
    "* Can use `@simd` to allow Julia to break some rules to make it happen\n",
    "    * But be careful, especially with `@simd ivdep`!\n",
    "* Depending on processor and types involved, can yield 2-16x gains with extraordinarily little overhead\n",
    "    * Smaller datatypes can improve this further; use `Float32` instead of `Float64`\n",
    "      if possible, `Int32` instead of `Int64`, etc.\n",
    "    * When buying a new processor, look for [AVX-512](https://en.wikichip.org/wiki/x86/avx-512) support"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
